# GTC2017 Instructions

If you are lost in one of the steps, just checkout one of the `gtc2017-sol-step` branches to get the solution and start working for the next step.

## Step 0: Execute and Profile FWI
- Read the README.md to know how to compile & profile FWI

- Execute the application with the 'profile' dataset:

```bash
cmake -DCMAKE_C_COMPILER=pgcc ..
make -j2
bin/fwi ../data/fwi_params.txt ../data/fwi_frequencies.profile.txt`
```

- Recompile with OpenMP enabled and execute the application again

```bash
cmake -DCMAKE_C_COMPILER=pgcc -DUSE_OPENMP=ON ..
make -j2
bin/fwi ../data/fwi_params.txt ../data/fwi_frequencies.profile.txt
```

- Recompile with Profiling enabled and profile FWI

```bash
cmake -DCMAKE_C_COMPILER=pgcc -DUSE_OPENMP=OFF -DPROFILE=ON ..
make -j2
bin/fwi ../data/fwi_params.txt ../data/fwi_frequencies.profile.txt
gprof <options>
```

## Step 1: Parallelize the application using OpenACC pragmas

```bash
cmake -DCMAKE_C_COMPILER=pgcc -DUSE_OPENMP=OFF -DUSE_OPENACC=ON ..
make -j2
bin/fwi ../data/fwi_params.txt ../data/fwi_frequencies.profile.txt
```

- First implementation will make use of CUDA Unified Memory also called 'Managed Memory' thus, you will need to modify the `pgcc` flags in CMakeLists.txt file and add the `managed` to the `-ta=tesla` target

- Initialize the data in the gpu by puting a `#pragma acc kernels` before the loop in function `set_array_to_constant` of `src/fwi_kernels.c`. Example:

```c
void set_array_to_constant(...)
{
    #pragma acc kernels
    for ( integer i = 0; i < length; i++ )
        array[i] = value
}
```

- Then put pragmas in all compute-intensive parts of src/fwi_propagator.c file.
  As you will have seen in step 0, those parts are:
   - vcell_TL
   - vcell_TR
   - vcell_BL
   - vcell_BR
   - scell_TL
   - scell_TR
   - scell_BL
   - scell_BR

  Although there are 8 parallel regions to complete, in reality all 'vcell' pragmas will be the same pragmas, and 'scell' pragmas will be very similar to the 'vcell' ones.

- Read all compiler output to find whether `pgcc` is generating a kernel or not (`-Minfo=accel` flag).

- If `pgcc` refuses to parallelize a compute region because he thinks there is a dependence and you know there is none, you can put a `#pragma acc loop independent` before each iteration level to force the compiler to parallelize the region. Example:

```c
#pragma acc kernels
#pragma acc loop independent
for (integer y=ny0; y < nyf; y++) {
    #pragma acc loop independent
    for (integer x=nx0; x < nxf; x++) {
        #pragma acc loop independent
        for (integer z=nz0; z < nzf; z++) {
```

- Functions that are called inside OpenACC parallel regions must be either inlined or declared with the `#pragma acc routine <type>` specifier.
  In our case you will have to add the `#pragma acc routine seq` to all `device` functions presents in `include/fwi/fwi_propagator.h` file.

- In `src/fwi_kernel.c` you will find the `propagate_shot` function that advances all timesteps.
  To prevent incorrect executions, put a barrier `#pragma acc wait` between iterations (after the second `exchange_stress_boundaries`).

## Step 2: Profile & Optimize the applicaiton

- Profile the application with `nvprof`:

```bash
nvprof bin/fwi ../data/fwi_params.txt ../data/fwi_frequencies.profile.txt
```
- Get the occupancy for all kernels with `nvprof`:
```bash
nvprof --metrics achieved_occupancy bin/fwi ../data/fwi_params.txt ../data/fwi_frequencies.profile.txt
```

- Or use Nvidia Visual Profiler (if available)

- You will see that Occupancy is low, 18% (ideal should be between 50 to 100%).
  You will also see that the large number of registers is the main cause of this low occupancy.
  To increase occupancy in exchange of more memory pressure (with register spills into local memory) we limit the number of registers per kernel.
  To do this you have to modify the `pgcc` flags and add a `maxregcount:128` to the `-ta=tesla` flag (`CMakeLists.txt` file).

- Execute and compare with the previous step

## Step 3: OpenACC Data regions

- We will stop using CUDA Unified Memory by removing the `managed` flag of `pgcc` compiler in `CMakeLists.txt`

- Next, in every parallel region we will have to specify all movement of data with `copyin`, `copyout` or `copy` clauses
  For instance all vcell kernels:

```c
const integer start  = ((nzf-nz0) + 2*HALO) * ((nxf-nx0) + 2*HALO) * (ny0 - HALO);
const integer end    = ((nzf-nz0) + 2*HALO) * ((nxf-nx0) + 2*HALO) * (nyf + HALO);
const integer nelems = end - start;

#pragma acc kernels copyin(szptr[start:nelems], sxptr[start:nelems], syptr[start:nelems], rho[start:nelems]) \
                    copy(vptr[start:nelems])
```

  Edit, all `vcell`, `scell` and `set_array_to_constant` functions. Arrays that are declared as `const real* restrict` can be considered as input dependences (`copyin`) and arrays that are just `real* restrict` are input/output dependences (`copy`)

- Execute & profile with nvprof

  Unfortunately H2D & D2H copies take more time that they should. In next step we will optimize this behaviour

## Step 4: Optimize data locality

- Use OpenACC `#pragma acc enter data create` and `#pragma acc exit data delete` pragmas to increase the locality in the GPU.
- In `alloc_memory_shot` function (`src/fwi_kernel.c`), and after all `malloc`s, put:

```c
const integer datalen = numberOfCells;
coeff_t cc = *c;

#pragma acc enter data create(cc)
#pragma acc enter data create(cc.c11[:datalen])
#pragma acc enter data create(cc.c12[:datalen])
...
```

- In `free_memory_shot` function, before all calls to `free` put:

```c
#pragma acc wait

#pragma acc exit data delete(c->c11)
#pragma acc exit data delete(c->c12)
...
#pragma acc exit data delete(c)
...
```

## Step 5: Add streams

- In this step we will use multiple streams to perform H2D,D2H copies concurrently with Kernel executions.

- In `include/fwi/fwi_propagator.h::78` you can find the `phase_t` enum:
```c
typedef enum {ONE_R, ONE_L, TWO, H2D, D2H} phase_t;
```
  Use those names to specify the streams.

- Add `async` clauses to use multiple streams and `#pragma acc wait(<stream list>)` to syncronize.
As an example:
```c
#pragma acc kernels ... async(phase) wait(H2D)
```
  or
```c
#pragma acc wait(TWO, D2H)
```

## Step 6: Add glue code to call CUDA Kernels

- Add preprocessor guards to compile the OpenACC code or to call the CUDA calls selectively:

In vcell/scell functions:

```c
{
#if !defined(USE_CUDA)
    ...
    for
        for
           for
             ...
#else
    void* stream = acc_get_cuda_stream(phase)

    #pragma acc host_data use_device(szptr, sxptr, syptr, rho, vptr)
    {
        compute_component_vcell_TL_cuda(..., stream);
    }
#endif
};
```

- And then recompile with CUDA and execute FWI:

```bash
cmake -DCMAKE_C_COMPILER=pgcc -DUSE_OPENMP=OFF -DUSE_OPENACC=ON -DUSE_CUDA_KERNELS=ON ..
make -j2
bin/fwi ../data/fwi_params.txt ../data/fwi_frequencies.profile.txt
```


